## 一次搞懂 DeepSeek 是什么｜如何使用｜能做什么｜更好的使用

### 一、DeepSeek 概览与背景

| 知识点 | 描述 |
| :--- | :--- |
| **公司背景** | **DeepSeek**（深度求索）是**幻方量化**旗下，致力于通用人工智能（AGI）研发的中国科技公司。专注于大语言模型（LLM）、多模态模型等核心技术的突破与创新。 |
| **成立时间** | 2023年成立。 |
| **创始人** | **梁文峰**。 |
| **公司理念** | 官网上醒目标语：**“以开源精神和长期主义追求普惠AGI”**，并一直在践行。 |
| **核心优势** | 1. 跻身全球大模型**第一梯队**。 2. 坚持模型**开源**。 3. 官网**免费开放**使用，践行技术普惠。 4. 以**远低于同行成本**实现高性能模型研发。 5. **无需科学上网**即可使用官方平台。 |
| **模型成本** | DeepSeek V3 的 API 价格（优惠期后）约为同类顶尖模型 **GPT-4o 的十分之一**，速度更快，推动了整个模型行业的价格普惠。 |
| **对行业影响** | **高性价比**推动行业竞争与进步，促使 Open AI、Google、阿里等巨头纷纷推出新模型，性能和价格开始向 DeepSeek 看齐。 |
| **理性看待** | DeepSeek 综合能力强，稳居第一梯队，但**并非在所有领域都是最强**，应客观看待其价值。 |

---

### 二、大模型分类基础科普（帮助理解产品）

| 分类维度 | 类别 | 描述 | 示例任务 |
| :--- | :--- | :--- | :--- |
| **输入数据类型** | **自然语言大模型** | 专注于**文本数据**处理。 | 文本生成、翻译、问答。 |
| | **视觉大模型** | 专注于处理**图像和视频数据**。 | 图像分类、目标检测、图像生成。 |
| | **多模态大模型** | 能够同时处理**文本、图像、音频、视频**等多种数据类型。 | 跨模态理解与生成。 |
| **应用领域** | **通用大模型** | 适用于多种任务和场景，具备**强大的泛化能力**。 | DeepSeek V3、GPT-4o。 |
| | **行业大模型** | 针对**特定行业**优化（如医疗、教育、金融）。 | 医疗诊断辅助模型。 |
| | **垂直大模型** | 针对**特定任务场景**优化。 | DeepSeek Coder（代码生成）、自动驾驶模型。 |

---

### 三、DeepSeek 核心产品矩阵（按时间线）

| 发布时间 | 模型名称 | 核心特点与分类 | 行业对标/性能（发布时） |
| :--- | :--- | :--- | :--- |
| 2023年11月2日 | **DeepSeek-Coder** | 开源代码大模型（垂直领域）。 | 支持多种编程语言的代码生成、调试、数据分析。 |
| 2023年10月29日 | **DeepSeek-LLM** | 通用型大模型（7B/67B Base & Chat 版本）。 | - |
| 2024年1月5日 | **DeepSeek-LLM-67B** | 670亿参数通用大模型。 | 中英文推理、编码等方面超过 LLaMA2-70B Base。 |
| 2024年2月5日 | **DeepSeek-Math** | 数学推理模型。 | 数学推理能力**逼近 GPT-4**。 |
| 2024年3月11日 | **DeepSeek-VL** | 专家混合视觉语言模型（多模态初步尝试）。 | 支持高级多模态理解（7B/13B）。 |
| 2024年5月 | **DeepSeek-V2** | 开源 MoE 通用大模型。 | 性能**比肩 GPT-4**，价格约为 GPT-4 Turbo 的 1%。 |
| 2024年6月17日 | **DeepSeek-Coder V2** | Coder 升级版（236B/16B）。 | 能力**超越当时最先进的闭源模型 GPT-4 Turbo**。 |
| 2024年9月5日 | **DeepSeek-V2.5** | V2 升级优化版。 | 优化了通用对话、写作任务、代码处理等。 |
| 2024年11月20日 | **DeepSeek-R-Letter** | 推理模型尝试。 | 支持数学、代码、复杂逻辑推理任务。 |
| 2024年12月13日 | **DeepSeek-VL V2** | VL 第二版（MoE 架构，3B/16B/27B）。 | 视觉能力大幅提升。 |
| 2024年12月26日 | **DeepSeek-V3** | **明星产品**，开源 MoE 通用大模型（671B）。 | 性能**对标 GPT-4o、Claude 3.5 Sonnet**，生成速度大幅提升。 |
| 2025年1月20日 | **DeepSeek-R1** | **明星产品**，推理模型正式版。 | 性能**对标 Open AI O1**，开放思维链（CoT）输出功能。 |
| 2205年1月28日 | **DeepSeek-Genius Pro** | 多模态模型（7B/1.5B）。 | **文生图模型**，7B 版本在基础测试中**击败 DALL-E 3 和 Stability Fusion**（目前仅支持 384 规格图像）。 |

---

### 四、明星产品 V3 与 R1 详解

#### 1. DeepSeek V3：通用指令模型

| 知识点 | 描述 |
| :--- | :--- |
| **模型架构** | 基于**混合专家（MoE）**架构的**通用模型**。 |
| **模型定位** | **全能选手**。能够轻松应对各种任务，如撰写邮件、编写故事、翻译、生成代码。 |
| **核心能力** | 强大的**自然语言理解**和**生成能力**，精准理解用户意图，流畅回应。 |
| **性能对比** | 综合能力与 **GPT-4o、Claude 3.5 Sonnet** 等顶尖闭源模型**不分伯仲**。在长文本评测、算法类代码场景、数学能力（美国数学竞赛、全国高中数学联赛）上表现突出，**大幅超越同类开源模型**。 |
| **API 价格** | API 价格约为同类顶尖模型的**十分之一**，且速度更快，性价比极高。 |
| **提问技巧** | 作为**指令模型**，高度依赖提示词（Prompt）质量。推荐使用结构化技巧 **“角色、背景、需求、输出”**（详见第六部分）。 |

#### 2. DeepSeek R1：推理模型

| 知识点 | 描述 |
| :--- | :--- |
| **模型生成** | 基于 DeepSeek V3 Base 进行**强化学习训练**，通过多阶段渐进训练优化形成。 |
| **模型定位** | 完全开源的**推理模型**，专注于**逻辑推理**和**问题解决**的**解题高手**。 |
| **核心能力** | 能够自主处理需要**多步骤分析、因果推断和复杂决策**的任务。 |
| **核心特点** | 提问后可直观看到模型**一步一步思考问题的过程**，即**思维链（Chain of Thought, CoT）**。 |
| **性能对比** | 性能**对标 Open AI O1**，在数学、代码和推理任务中实现相当的性能。 |
| **API 价格** | API 价格约为 V3 的两倍，但仅为 **Open AI O1 的 4.5 分之一**，且**官网可免费试用**。 |
| **提问技巧** | 提问时应**把它当成一个人**，遵循提问的**“黄金三角结构”**（汉堡结构：**背景、需求、方向**），**不推荐过度使用提示词技巧或引导其推理过程**。 |

#### 3. **指令模型 vs 推理模型** 适用场景对比

| 问题类型 | 特点 | **指令模型（V3/GPT-4o）** | **推理模型（R1/O1）** |
| :--- | :--- | :--- | :--- |
| **认知性问题** | 事实、科学解释（是什么、为什么） | 快速检索，提供**客观事实**。 | 提供**更深入的解释**和关联知识。 |
| **实践性问题** | 具体步骤、方法、策略（怎么做、如何实现） | 根据规则/模板，生成**具体步骤**。 | 结合上下文，动态调整，提供**更灵活建议**。 |
| **伦理性问题** | 价值观判断（是否应该） | 提供基于伦理原则的**标准答案**或常见观点。 | **多角度分析**，提供更平衡的观点。 |
| **封闭性问题** | 明确答案范围/具体事实（是/否、具体值） | 快速检索，提供**准确答案**。 | 提供更精确或更个性化的答案（效率不如指令模型）。 |
| **开放性问题** | 激发思考和讨论（没有固定答案） | 生成**多样化**的回答，提供多种可能性。 | 通过逻辑推理，提供**更深入、更有条理**的回答。 |
| **适用总结** | **效率优先、结果优先**（查天气、简单数学、重置路由器等**简单任务**） | **推理优先、深度优先**（开放脑洞题、复杂逻辑推理、伦理题等**复杂任务**） |

---

### 五、DeepSeek 官方平台使用与替代方案

#### 1. 官方使用

* **访问地址**：`deepseek.com` 或 `chat.deepseek.com`。
* **模型选择**：默认使用 **V3 模型**；勾选 **“深度思考”** 则切换为 **R1 模型**（会展示思维链）。
* **功能选择**：可选择 **“联网搜索”** 功能，模型会先检索网络内容再生成回答。
* **APP**：支持网页版和手机 APP，APP 出现服务器繁忙的频率低于网页版。

#### 2. 服务器繁忙（**纠错与建议**）

* **问题现状**：DeepSeek 官网目前偶发 **“服务器繁忙”** 提示。
* **原因分析**（推测）：全球用户体量大、可能存在 DDOS 攻击，以及出于 **成本和资源管理** 的考虑（模型免费试用很良心，服务稳定需要成本）。
* **解决建议**：
    * **不要点重试**（通常无效）。
    * 尝试**新开一个聊天窗口**，重新发送问题（成功率较高）。
    * **优先使用手机 APP**。
    * **不使用 R1 模型**（不勾选深度思考）时，繁忙频率较低。

#### 3. 第三方平台使用（满血 R1 替代方案）

由于官方平台有时繁忙，可考虑使用部署了**满血开源 R1** 的第三方平台。

* **推荐平台**：**腾讯元宝**。
    * **优势**：满血支持 R1、支持联网搜索、速度快、**免费**、背景硬（大厂抗压能力强）。
    * **注意**：元宝**默认模型是混元**，每次打开新聊天框**需手动切换到 DeepSeek 模型**。
    * **多模态增强**：在元宝上传图片，会使用腾讯混元系多模态模型解析图片内容，再发送给 DeepSeek 模型回答（优于 DeepSeek 官网的文字识别策略）。
* **微信灰度测试**：部分用户已内测到微信 AI 搜索功能，其中的 **“深度思考”** 功能由 DeepSeek R1 提供（包含思考过程、消息源）。

---
### 六、DeepSeek 能为我们做什么？（示例与启示）

* **核心观点**：AI 不仅仅是一个聊天框。**时代变了，尽早让 AI 融入生活，主动适应 AI 的存在**。拥抱新技术是职业素养，否则将被时代抛弃。
* **通用场景**：遇到问题，**先去问 DeepSeek（选中联网搜索、或深度思考 R1）**，比百度、谷歌更高效，AI 在绞尽脑汁理解问题。

#### 1. 职业应用示例（由 DeepSeek R1 整理）

| 职业 | DeepSeek 可提供的帮助（示例） |
| :--- | :--- |
| **教师** | 快速生成课堂教案、设计互动练习题、整理学科知识框架。 |
| **程序员** | 辅助代码开发、自动补全函数逻辑、解释复杂算法原理。 |
| **市场策划** | 生成创意文案、自动产出节日营销文案、分析竞品广告策略。 |
| **自媒体博主** | 批量生产内容、生成短视频脚本创意、优化文案标题关键词。 |
| **创业者** | 进行商业分析、生成用户画像模板、预测市场趋势变化。 |
| **设计师** | 激发创作灵感、生成 UI 配色方案、解析流行设计趋势。 |
| **科研人员** | 加速文献研究、自动总结论文核心观点、生成实验数据分析模板。 |
| **学生** | 加速学习效率、一键整理学科知识框架、一键生成题库。 |

#### 2. 个性化提问模板（解决“我能做什么”的疑问）

* **提问方式**：直接问 AI **“你能给我带来什么帮助？”**
* **模板（越详细越好）**：
    > “小弟你好，我叫 XXXXX，我今年 XX 岁，性别 XXX，职业 XXX，平常的工作内容是 XXXX。我想要使用你，但是我不知道你能给我带来什么帮助？你可以帮我解答这个问题吗？谢谢你。”
* **案例启示**：连 **“建筑工人”**（搬砖和泥盖房子）都能获得 AI 从**工作优化、安全防护、健康管理、职业发展、生活帮手**等各方面提供的详细建议和操作示例。
* **结论**：不要觉得自己的工作不涉及互联网，AI 就没有用。**最了解你的还是你自己，去问 AI 吧。**

> 在大部分场景下AI都比我们去问人要更有效率。那如果你非要和我聊聊模型的幻觉问题，我会回答你：难道问人就一定是对的？

---

### 七、如何用好 DeepSeek：提问与 Prompt 技巧


* **高价值文案**
* 在我们程序员群体有个看不见，摸不着的能力，它叫检索能力，也可以称之为解决问题的能力。简单来说，就是遇到问题。谷歌、百度去检索出相关联的内容，并且尝试去解决。所以，我们程序员私下里面也会戏称自己是面向谷歌、百度编程。有人会问，这也是一种能力吗？没错，他是不要觉得谷歌、百度人人都会，大部分人遇到问题之后，谷歌、百度就是解决不了，你难道没有想过这是为什么吗？还是你真的以为所谓的大佬就是无所不能的？你问什么大佬都会。其实很多问题上，你询问的大佬也不是特别清楚。

* 大家的脑袋差不了多少都装不了太多的东西，对吧？但是他们为什么能回答你？因为他们除了经验之外，还有极强的检索能力，你在问问题的同时，如果你的问题描述没有很大的缺陷，这些人往往能通过你的描述快速提炼关键词。去检索并且能从大批的结果中检索出一支匹配的正向结果反馈给你。当然，**如果你问问题的描述就驴头不对马嘴，那对不起，不予回复。**

* 所以建议大家问别人问题，没有得到回复的时候多想一想自己对问题的描述是否清晰。包括大家给我的私信以及社群里的一些问题，那如果你问我一个问题，描述比较清晰，我只要有时间看到就会回复，但是如果你问的问题，描述本身就不清晰，你总不能再让我去追着问你问题，为了解决你的问题，对吧？这不合理。哎，问你问题，为了解决你的问题，对没毛病，

* 所以向搜索引擎提问就是门学问，向人提问同样也是门学问，区别是向搜索引擎提问要更精准。向人提问，很大程度上就是让别人帮你精准，所以向搜索引擎提问，这就是检索能力的一种体现，它是由**检索经验的累积，再加上关键词的提炼构成的**，你是不是想到了什么？没错AI时代的来临，最先取代的就是搜索引擎，与之关联的检索能力的载体就由搜索引擎转到了AI身上，而我们在搜索引擎中的关键词提炼映射到AI上就是prompt——提示词，

向模型提问是使用 **DeepSeek** 的核心，最终结果的好坏，归根结底取决于提问的质量。

#### 1. 提问效果不佳的两大障碍

许多人难以向 AI 提出好问题并获得满意结果，原因可归结为两类：

* **障碍一：不懂 Prompt 技巧（提示词工程）**
    * **原因**：目前大模型存在**理解能力有限**等问题。
    * **Prompt 的关键作用**：
        * 帮助模型更清晰地**捕捉需求**，避免误解。
        * 引导模型生成**更相关、更准确、更详细**的回答。
        * 降低模型生成**带有偏见或不准确信息**的风险。
* **障碍二：不会提问（本质原因）**
    * 这不是指单纯不会向模型提问，而是**缺乏基本的提问能力**（向人提问也同样适用）。
    * **表现**：提问描述中遗漏了解决问题所需的**关键信息**，导致回复无法针对性解决问题。
    * **核心结论**：提问的关键不在于答案本身，而在于**如何清晰地提问**。

#### 2. 问题的本质与构成

了解问题的本质有助于构建高质量的提问。

* **哲学定义**：问题是指某种**现实状态**与**期望状态**之间的**差距**，或是对未知现象、矛盾、障碍的表达。可以是具体的提问，也可以是抽象的困惑。 
    * **案例示例**：
        * 原始人：发现火会熄灭（现实） $\rightarrow$ 渴望**如何保存火种**（期望）。
        * 现代人：发现手机续航不足（现实） $\rightarrow$ 渴望**如何提升电池容量**（期望）。

#### 3. 问题的五大分类（提问的逻辑基础）

针对不同的问题类型，模型处理方式和所需的提问侧重点不同。

| 序号 | 问题类别 | 定义与目标 | 典型特征（开头） | 案例示例（均需保留） |
| :--- | :--- | :--- | :--- | :--- |
| **1** | **认知性问题** | 答案是**客观事实或科学解释**，目标是获取知识或理解现象。 | **是什么？为什么？** | “天空为什么是蓝色的？” “人类的大脑是如何存储记忆的？” |
| **2** | **实践性问题** | 答案是**具体的步骤、方法或策略**，目标是解决实际问题或完成任务。 | **怎么做？如何实现？** | “如何提高团队效率？” “如何在 30 天内提高英语口语水平？” |
| **3** | **伦理性问题** | 答案取决于**价值观**，没有唯一正确答案，旨在引发深度思考。 | **是否应该？** | “人工智能是否应该有道德评判？” “动物实验是不是应该被禁止？” **（引申：是否应该允许克隆人？）** |
| **4** | **封闭性问题** | 有**明确答案范围或具体事实**，适合用于确认信息或快速决策。 | **是/否？（具体值）** | “水的沸点是多少？” “你吃过午饭了吗？” “今天开会吗？” |
| **5** | **开放性问题** | **没有固定答案**，旨在激发思考和讨论，适用于深度探讨或创意发散。 | **是什么？如何应对？** | “幸福的本质是什么？” “如何应对全球气候变化？” **（引申：未来的城市交通会是什么样子，如空中飞车、传送门）** |

> 问题就想把钥匙，不同的钥匙能够打开不同的门。

#### 4. 提问的黄金三角结构（汉堡结构）

- 你是不是也遇到过这种情况，你们想请教别人，对方却听不懂你的意思，或者讨论问题时总是抓不到重点。那其实问题的核心不在答案，而是在如何问，也就是提问的技巧。
- 一个好的提问由三部分组成，我们称它为黄金三角结构，也可以叫汉堡结构。

这是 **人与人之间** 和 **推理模型（R1）** 提问的基础，也是指令模型技巧的基础。

| 结构部分 | 汉堡比喻 | 核心要点 | **对模型的作用** |
| :--- | :--- | :--- | :--- |
| **背景** | 面包（不可或缺） | **为什么要这样做？**（现状、前提、困境） | 帮助模型理解你的**立场和现状**，进行定向回答。 |
| **需求** | 肉饼（最核心） | **你要做什么？**（核心任务、要解决的问题） | **越细越好**。需求越像手术刀，答案越像特效药。 |
| **方向** | 芝士（锦上添花） | **想要达到什么样的效果？**（控制回答范围、输出风格） | 明确回答的**范围和风格**，使结果更契合预期。 |

#### 5. 指令模型（V3/GPT-4o）的结构化 Prompt 技巧

哪怕你懂得再多的 prompot 技巧，不会提问都是扯淡。你只要学会提问，哪怕不懂prompt 技巧，只靠这些提问技巧向模型提问，也足以能拿到60分，达到及格线。


#### 6. 通用指令模型的特点与局限

通用指令模型（例如 **DeepSeek V3**、**GPT-4o**）的输出高度依赖用户提供的 **Prompt（提示词）技巧**，因为模型本身存在以下固有缺陷：

##### 指令模型的固有缺陷

1.  **缺乏真正的理解能力**：
    * 大模型主要通过**统计模式**生成文本，并非真正理解语言的含义或背后的逻辑。
    * 这容易导致模型生成**看似合理，实则错误的答案**，或无法区分事实与虚构，从而产生**虚假信息**（即“幻觉”）。
2.  **推理和逻辑能力不足**：
    * 特别是在处理复杂任务时，指令模型缺乏必要的推理和逻辑能力。
    * 在**复杂逻辑推理、数学计算**以及**因果推断**方面表现往往不好。

##### Prompt 技巧的关键性

鉴于上述缺陷，指令模型的**输出质量**与其提示词的质量和具体性直接挂钩：

* **对提示词的依赖性高**：玩指令模型，要求用户必须具备一定的**提示词能力**。
* **提示词的作用**：清晰、具体的 Prompt 能帮助模型更好地**捕捉用户需求**，避免误解，并引导模型生成**更相关、更准确、更详细**的回答。
* **不良后果**：模糊或不明确的提示词，可能导致模型输出**无关或低质量**的内容。

只需在“汉堡结构”的基础上增加 **“角色”** 和明确 **“输出”**，八字通吃。

| 核心要素 | 对应汉堡结构 | 核心要点 | 案例演示（写气候文章） |
| :--- | :--- | :--- | :--- |
| **角色** | 增项 | **明确模型的身份/人设**（专家、作家、老师）。 | “假设你是一位**环境科学家兼科普作家**” |
| **背景** | 背景 | **为什么要这样做？**（现状、上下文） | “全球气候变化日益严峻，公众对气候问题的关注度不断提升，但理解深度有限。” |
| **需求** | 需求/任务 | **核心要解决的问题**（越详细越好）。 | “请你撰写一篇通俗易懂且具有科学依据的文章，用来提高公众对气候变化的认知，并激发行动。” |
| **输出** | 方向/格式 | **指定输出的形式或格式**（达到什么效果）。 | “输出**1000字左右**的文章，包含气候变化的原因、影响、应对措施以及行动建议，**语言生动，数据准确**。” |

* **Prompt 优化**：如果自己写不好，可以使用 AI 帮你优化 Prompt。
    * **模板思路**：让 AI 扮演“提示词优化专家”，要求它基于“角色、背景、需求、输出”四个核心来优化你提供的模糊提示词。

> **举例**：
> 你是一个提示词优化专家，用户当前提示词较为模糊，缺乏具体指导。 请帮用户优化关于《xxxxxx》 的提示词，基于角色、背景、需求、输出四个核心，使其更具结构性和可操作性，帮助用户更高效地完成任务。 优化后的提示词模板，包含明确的角色定义、背景描述、需求细化及输出要求，并提供优化说明，解释每一步的改进逻辑。

#### 7. 推理模型（R1/O1）的提问技巧

* **核心原则**：**把它当成一个人去提问**，遵循“汉堡结构”即可。
* **不推荐**：**不要试图干涉它的推理过程**，如加入“你应该怎么做”、“你先做什么再做什么”等引导思考步骤的词汇，这可能会限制其自主推理逻辑。
* **修正方式**：如果 R1 回答不满意，**指出回答中令你不满意的点**，它会自我质疑并修正。
* **应用场景**：**专注于复杂任务**，简单任务（查天气、简单计算）用 V3 更高效。

确实网上有很多博主介绍各种推理模型提问的小技巧。但是对他们有用，对你们不一定有用，因为本质上推理模型不存在系统的技巧，推理你就可以理解为是思考思考的方向是不固定的。问题的种类也是多样的，在一定的场景下确实可以根据习惯总结出一些适合自己的小技巧，但是换个人换个场景，它并不一定适用。所以我只推荐大家记住问题的构成，把它当人去问就行了

另外我要多讲一句术业有专攻，对吧？大家不要觉得 R1 好像很聪明，什么问题都用 R1 去问。这种推理模型其实是为了一些复杂任务场景而生的，那比如你要问去年今天是星期几？这种简单的小问题，你使用 R1 去问多少有点大材小用，而且它还要花很长的时间去做推理，你不如直接用 V3 去问，速度又快又准确。

---
好的，这是对您提供的文稿中关于 **DeepSeek V3 (指令模型) 与 R1 (推理模型) 的适用性对比**的知识点整理，已保持逻辑结构并纠正了潜在的错别字。

---

#### 8. DeepSeek V3 与 R1 的适用性对比

选择 **V3 (指令模型)** 还是 **R1 (推理模型)**，取决于你所提问的**问题类型**。虽然 R1 在大多数能力上更强，但 V3 在追求**效率**的场景下更具优势。

##### 1. 不同问题类型下的处理方式对比

| 问题类型 | DeepSeek V3（指令模型）的处理方式 | DeepSeek R1（推理模型）的处理方式 |
| :--- | :--- | :--- |
| **认知性问题** (如：**为什么天空是蓝色的**？) | 通过预训练知识库**快速检索**，提供**准确的科学解释或客观事实**。 | 通过**逻辑推理**和上下文理解，提供**更深入的解释**和关联知识。 |
| **实践性问题** (如：**如何提高团队效率**？) | 根据预定规则或模板，生成**具体的步骤、方法或策略**。 | **结合上下文和用户需求**，动态调整解决方案，提供**更灵活的建议**。 |
| **伦理性问题** (如：**人工智能是否应该有道德判断**？) | 提供基于伦理原则的**标准答案**或常见的观点。 | 通过**多角度分析**，结合推理逻辑，提供**更平衡的观点**。 |
| **封闭性问题** (如：**水的沸点是多少**？) | **快速检索**，提供**准确的答案**。 | 通过上下文理解，提供**更精确或更个性化的答案**（答案实质不变，但多了一层推理）。 |
| **开放性问题** (如：**幸福的本质是什么**？) | 生成**多样化**的回答，提供多种可能性。 | 通过**逻辑推理和上下文分析**，提供**更深入、更有条理**的回答。 |

##### 2. 模型选择的核心原则：效率 vs 深度

尽管 R1 的整体能力更强，但它会**先生成推理文本**再给出答案，因此在简单任务上效率不如 V3。

| 模型 | 核心原则 | 适用场景和任务（追求**准确**和**高效**） |
| :--- | :--- | :--- |
| **DeepSeek V3 (指令模型)** | **效率优先、结果优先** | 适用于**简单、信息获取类**的任务。你需要一本**精准的工具书**，快速拿到答案，不啰嗦。 |
| | | **案例**：快速查天气、算数学题、找明确操作步骤（如**怎么重置一下路由器**）、只需要拿到结果的认知性问题（如**地球为什么是圆的**）、封闭性问题（如**珠峰的高度是多少**）。 |
| **DeepSeek R1 (推理模型)** | **推理优先、深度优先** | 适用于**复杂、需要深入分析**的任务。它是一个**全能型顾问**，提供多角度的深度解析。 |
| | | **案例**：开放性的**脑洞题**（如**帮我写一首情诗**）、**复杂的逻辑推理题**（如分析 AI 会让哪些职业消失）、**伦理题**（如**无人驾驶如何选择救人顺序**）。 |

### 八、DeepSeek 更多玩法：本地部署与 AI 知识库


#### 1. 本地部署（残血版）

轻量级量化版是针对资源充足但又不想投入巨额资金的朋友们提供的**消费级部署方案**。

* **技术原理（量化）**：通过**降低数值精度**来压缩模型体积的技术。
* **具体案例**：Ans Loss AI 在 Hugging Face 上提供了动态量化的 R1 版本。
    * 将 671B 参数、720G 体积的模型压缩到最小约 **131G**（约 1.58-bit 量化）。
    * 甚至可以在单台消费级机器 **Mac Studio** 上运行。

* **模型版本**：主要是**蒸馏版**（残血版），指经过微调的**小参数版本**。
* **部署价值**：作为**备选方案**应对极限情况，并非玩具。
    * **数据安全**：**数据存储在本地**，避免泄露（适用于有数据安全规定的公司）。
    * **网络限制**：**完全离线使用**，不受弱网环境限制。
    * **内容自由**：**内容输出更自由**，没有严格审查机制。
    * **灵活性**：可使用私有数据**微调模型**，构建独有 AI 工具链。
* **部署工具**：**Ollama**（Windows/Mac 均支持）。
    * **步骤**：下载 Ollama $\rightarrow$ 安装 $\rightarrow$ 在 Ollama 官网 models 页面选择 DeepSeek R1 版本 $\rightarrow$ 复制命令 $\rightarrow$ 在终端/命令提示符中运行。
    * **模型选择**：**根据自己的电脑配置（显存）来选择参数集**。最简单方法是截图电脑配置问 DeepSeek 适合哪个参数集。
* **API 调用**：Ollama 默认服务端口是 `11434`，可用于调用本地模型 API。
* **可视化界面**：推荐使用 **Chrome 扩展** **“Pace Access”**，可连接本地 Ollama 模型进行聊天，也支持管理提示词和兼容 Open AI 格式的在线 API。

#### 2. 满血版 R1 部署（高成本方案）

* **满血定义与性能妥协**：
    * **是否为满血版？** 仍然属于**满血版本**。判断标准是参数规模和架构完整性（泛化能力），量化版**没有删减参数或改变模型设计**。
    * **性能影响**：量化版本只是在部分层上降低了精度，因此可称之为**性能妥协版**。在某些问答场景下**可能会有性能损失**。
* **与残血版区别**：量化版（满血版）要比所谓的**蒸馏版**（**残血版**，即经过微调的小参数版本）强大很多。


部署 671B 满血版 R1 模型（全量模型体积约为 **720G**）大致有以下三种方案，主要区别在于性能和成本：

| 方案类别 | 核心特点 | 成本估算（单次硬件投入） |
| :--- | :--- | :--- |
| **极致性能/全量不删减** | 追求最高性能，不进行任何删减。 | 约 **55 万人民币** |
| **性价比最优（K-Transformer）** | 基于清华大学的 K-Transformer 架构（核心为异构计算、智能任务分配、多级优化策略）。 | 约 **10 万人民币** |
| **轻量级量化版（消费级）** | **唯一可在消费级机器上部署满血 R1 的方法**。 | 约 **5-6 万人民币** |


#### 3. 在线模型 API 调用（付费/免费）

DeepSeek 官方 API 虽便宜，但充值功能有时无法使用，可考虑第三方平台。

**注意**：自 **02/26 日**起，DeepSeek 官网已重新开启账户充值入口。速度不快不慢，但在每日 **00:30-08:30** 时段，**V3 是原价的 50%，R1 是原价的 25%**。

| 平台名称 | 注册/使用优惠 | V3 API 价格（输入/输出） | R1 API 价格（输入/输出） |
| :--- | :--- | :--- | :--- |
| **OpenRouter** | 提供**免费接口调用** / 有限制 | 2￥ / 8￥ | 4￥ / 16￥ |
| **腾讯云** | 无 | 2￥ / 8￥ | 4￥ / 16￥ |
| **阿里云百炼** | 注册送 **100 万 Token** | 2￥ / 8￥ | 4￥ / 16￥ |
| **火山引擎** | 注册送 **50 万 Token** | 2￥ / 8￥ | 4￥ / 16￥ |
| **硅基流动** | 注册送 **14 ￥ 额度** | 2￥ / 8￥ | 4￥ / 16￥ |

#### 4. 私人 AI 知识库搭建（RAG 技术）

* **推荐方案**：**Chat-Studio** 开源项目。
    * **优势**：**安装非常简单**（下载包双击安装），功能不错，UI 友好，**适合普通用户**。
    * **模型配置**：可配置本地 Ollama 模型，也可配置 OpenRouter 等在线 API。
    * **知识库创建**：需要选择**文本嵌入模型（Embedding Model）**，用于将文件内容向量化。
    * **使用方式**：创建知识库 $\rightarrow$ 选择嵌入模型 $\rightarrow$ 上传文件 $\rightarrow$ 在小助手里选中该知识库进行问答。
    * **注意**：知识库创建后，**嵌入模型不可更改**。

#### 5. 模型知识持续学习的三种方式

| 方式 | 描述 | 优点 | 缺点/成本 |
| :--- | :--- | :--- | :--- |
| **长文本提示** | 直接将大量文本（如论文）复制到输入框，让模型根据上下文总结。 | 操作简单。 | 仅在当前对话有效，有上下文限制，容易超出 Token 上限。 |
| **大模型微调** | 将数据直接喂给模型本身去学习。 | 回答效果好，知识融入模型。 | **成本高昂**，知识**时效性差**，依赖数据集质量。 |
| **RAG 技术** | **（主流方案）**外挂一个知识库，问问题时先从知识库匹配相关内容，再将**内容 + 问题**一起发送给模型。 | 成本低、**可实时调整数据**、知识**时效性高**。 | 需要额外技术搭建。 |

如果想要本地部署一个私人 AI 知识库，有多种开源方案可供选择（如 Max KB, Dify, Anything LLM, FastGPT, RAGFlow 等）。

| 项目名称 | 部署难度 | 功能和 UI 评价 |
| :--- | :--- | :--- |
| **Max KB, Anything LLM** | 简单 | 功能和 UI 界面**一般**。 |
| **Dify, FastGPT, RAGFlow** | 较高 | 功能和 UI 都不错，特别是 **FastGPT** 和 **RAGFlow** 功能**十分强大**，但所需的资源和部署难度也更高。 |

* **个人推荐优先级排序：**
    $$\text{FastGPT} > \text{RAGFlow} > \text{Dify} > \text{Anything LLM} > \text{Max KB}$$

* 这里最推荐方案：Cherry-Studio（对普通用户最友好）。对于追求**简单易用**、不想进行复杂配置的普通用户，**Cherry-Studio** 是一个非常合适的开源知识库产品。

* **项目特点**：
    * 这是一个较新的开源项目，但其 GitHub Star 数量**飙升速度很快**（曾从 5k 迅速升至 **15k Star**）。
    * 功能不错，UI 也还可以。
* **部署优势（用户友好）**：
    * **私人部署非常简单**：只需**下载对应的安装包，双击安装**即可完成，无需复杂的配置。
    * 它满足了普通人想要搭建私人 AI 知识库但又不想进行复杂配置的需求。
* **环境依赖**：
    * 该方案默认本地已通过 Ollama 服务安装了 **DeepSeek R1** 大模型和 **Nomad Embed Test** 文本嵌入模型。